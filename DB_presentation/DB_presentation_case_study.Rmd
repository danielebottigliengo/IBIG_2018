---
title: "\\Large\\textbf{Introduction to Bayesian Computation and Application to Regression Models and Survival Analysis}"
subtitle: "\\large\\textbf{\\textrm{IBIG 2018}}"
author: "\\centering\\underline{\\textbf{Daniele Bottigliengo}}\\thanks{\\tiny Unit of Biostatistics, Epidemiology and Public Health, Department of \\newline Cardiac, Thoracic, Vascular Sciences and Public Health, University of Padua, Italy}"
date: "\\centering\\emph{Padova, Italy, November 22, 2018}"
header-includes:
   - \usepackage{booktabs}
   - \usepackage{subfig}
   - \usepackage{multicol}
   - \usepackage{rotating}
   - \usepackage{mathtools}
   - \usepackage{pgfplots}
   - \usepackage{listings}
   - \usepackage{multirow}
   - \usepackage{amssymb}
   - \usepackage{pifont}
   - \usepackage{tikz}
   - \usepackage{graphics}
   - \usepackage{hyperref}
   - \usepackage{enumerate}
   - \hypersetup{
    colorlinks = true,
    linkcolor = blue,
    filecolor = magenta,      
    urlcolor = cyan,}
output: 
  beamer_presentation: 
    fig_caption: yes
    keep_tex: yes
    theme: Padova
classoption: [a4paper]
biblio-style:  alphabetic
biblio-citestyle: authoryear
bibliography:
   - bibliography_lab.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(comment = '')
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(warning = FALSE)
knitr::opts_chunk$set(message = FALSE)
```

```{r, include = FALSE, message = FALSE}
library(tidyverse)
library(rstan)
  options(mc.cores = parallel::detectCores() - 1)
  rstan_options(auto_write = TRUE)
  Sys.setenv(LOCAL_CPPFLAGS = c('-march=native'))
library(bayesplot)
library(loo)
library(survival)
library(survminer)
library(knitr)
library(broom)
  
load(here::here("lab/logistic_case_study/logit_analysis.rda"))
load(here::here("lab/survival_case_study/survival_analysis.rda"))
load(here::here("data/logistic_case_study.rda"))


# Rescale covariates for computational ease
db_ovarian <- ovarian

db_ovarian_scaled <- ovarian %>%
  janitor::clean_names() %>%
  dplyr::select(age, resid_ds, ecog_ps, rx, futime, fustat) %>%
  mutate(age = age/100) %>%
  mutate_at(
    vars(age:rx), funs(as.numeric(scale(x = ., scale = FALSE)))
  ) %>%
  mutate(futime = futime/365.25)

ovarian_scaled_list <- list(
  n_obs = db_ovarian_scaled %>% filter(fustat == 1) %>% nrow(),
  n_cens = db_ovarian_scaled %>% filter(fustat == 0) %>% nrow(),
  y_obs = db_ovarian_scaled %>% filter(fustat == 1) %>% .[["futime"]],
  y_cens = db_ovarian_scaled %>% filter(fustat == 0) %>% .[["futime"]],
  k = ncol(db_ovarian_scaled) - 2L,
  x_obs = db_ovarian_scaled %>%
    filter(fustat == 1) %>%
    dplyr::select(age:rx) %>%
    as.matrix(),
  x_cens = db_ovarian_scaled %>%
    filter(fustat == 0) %>%
    dplyr::select(age:rx) %>%
    as.matrix()
)
```

# Survival Analysis Case Study

## Survival Ovarian Cancer

- Randomized trial comparing treatment of patients with advanced
  ovarian carcinoma (stages $IIIB$ and $IV$) [@edmonson_1979]
  
- Two groups of patients:
  \begin{itemize}
    \item{Cyclophosphamide alone ($1 \> g/m^{2}$)}
    \item{Cyclophosphamide ($500 \> \mu g/m^{2}$) plus Adriamycin 
        ($40 \> \mu g/m2$)}
  \end{itemize}
  
- Intravenous (IV) injection every $3$ weeks

## The dataset (1)
\begin{itemize}
\setlength\itemsep{1em}
  \item{$26$ women enrolled}
  \item{The following information were retrieved:}
  \begin{itemize}
    \item{Age}
    \item{Presence of residual disease}
    \item{ECOG performance}
  \end{itemize}
\item{Median follow-up time in the Cyclophosphamide group: 
      $448$ days}
\item{Median follow-up time in the Cyclophosphamide plus 
      Adriamycin: $563$ days}  
\item{$12$ patients died during the study and $14$ were right-censored}
\end{itemize}

## The dataset (2)
\tiny
```{r}
ovarian_print <- ovarian %>% 
  rename(
    follow_up_days = futime, status = fustat, 
    residual_disease = resid.ds, treatment = rx,
    ecog_performance = ecog.ps
  ) %>% 
  mutate(
    status = factor(
      if_else(status == 0, "alive", "dead")
    ),
    residual_disease = factor(
      if_else(residual_disease == 1, "no", "yes")
    ),
    treatment = factor(
      if_else(treatment == 1, "Cyclo", "Cyclo + Adria"))
  )

kable(ovarian_print %>% slice(1:10))
```

## Exploratory data analysis (1)
```{r, fig.height = 6, fig.width = 8}
p_trt
```


## Exploratory data analysis (2)
```{r, fig.height = 6, fig.width = 8}
p_resid_ds
```

## Exploratory data analysis (3)
```{r, fig.height = 6, fig.width = 8}
p_ecog_ps
```

## Survival Model

Weibull parametric proportional hazard model:
  $$
  f \left( t \vert \alpha, \sigma \right) = \frac{\alpha}{\sigma} \left( \frac{t}{\sigma}\right)^{\alpha - 1} e ^{ - \left( \frac{t}{\sigma} \right)^{\alpha} }
  $$
where:

\begin{itemize}
 \item{$\alpha$ is the shape parameter}
 \item{$\sigma$ is the scale parameter defined as $\sigma = e ^{ - \left( \frac{\eta}{\alpha} \right) }$}.
 \item{$\eta$ is the linear predictor and it can be expressed as 
       function of some covariates}
\end{itemize}

## Data simulations
How to proceed:
\begin{enumerate}
  \item{Draw a parameter value from the prior distributions}
  \item{Simulate data according to the model and the parameters 
        values drawn from the priors}
  \item{Are simulated plausible?}
  \item{Fit the model to the simulated data}
  \item{Are true parameters values included in the posterior 
        distributions?}
\end{enumerate}

## Inspect simulated data
```{r, fig.width = 9, fig.height = 5}
ppc_uniform
```

## Inspect simulated data
```{r, fig.width = 9, fig.height = 5}
ppc_weakly
```

## Recover the parameters values
```{r, fig.width = 9, fig.height = 5}
recover_fake_weibull_centered
```

## The model: data block
\scriptsize
```{r, echo = TRUE, results = "hide"}
"
data {

  int<lower = 0> n_obs;             // Number of deaths
  int<lower = 0> n_cens;            // Number of censored
  vector[n_obs] y_obs;              // Death vector
  vector[n_cens] y_cens;            // Censored vector
  int<lower = 0> k;                 // Number of covariates
  matrix[n_obs, k] x_obs;           // Design matrix for deaths
  matrix[n_cens, k] x_cens;         // Design matrix for censoring

}

"
```

## The model: parameters block
\scriptsize
```{r, echo = TRUE, results = "hide"}
"
parameters {

  real<lower = 0> alpha;           // Alpha parameter on the log scale
  real beta_0;                     // Intercept
  vector[k] beta;                  // Coefficients of covariates

}
"
```

## The model: model block
\scriptsize
```{r, echo = TRUE, results = "hide"}
"
model {

  // Linear predictors
  vector[n_obs] eta_obs = beta_0 + x_obs * beta;
  vector[n_cens] eta_cens = beta_0 + x_cens * beta;

  // Define the priors
  target += normal_lpdf(alpha | 0, tau_alpha) +
            normal_lpdf(beta_0 | 0, tau_beta_0) +
            normal_lpdf(beta | 0, 1);

  // Define the likelihood
  target += weibull_lpdf(y_obs | alpha, exp(-eta_obs/alpha)) +
            weibull_lccdf(y_cens | alpha, exp(-eta_cens/alpha));

}
"
```


## Fit the model to the real data
Before fitting the model to the real data, a data pre-processing phase
was applied to ease the sampling process

\begin{itemize}
  \item{Age in years divided by a constant ($100$)}
  \item{Follow-up time from days to years}
\end{itemize}

Once the model is fitted to the observed data, it is possible to
proceed by evaluating two important aspects of the analysis:
\begin{itemize}
  \item{MCMC diagnostics}
  \item{Posterior calibration}
\end{itemize}


## MCMC diagnostics: $R_{hat}$ and $ESS$
```{r, fig.width = 10, fig.height = 6}
r_hat_weibull <- rhat(
  model_list_surv$weibull, pars = c("alpha", "beta_0", "beta")
)
n_eff_weibull <- neff_ratio(
  model_list_surv$weibull, pars = c("alpha", "beta_0", "beta")
)

p1 <- mcmc_rhat(r_hat_weibull)
p2 <- mcmc_neff(n_eff_weibull)

ggpubr::ggarrange(
  p1, p2, ncol = 2L, nrow = 1L
)
```

## MCMC diagnostics: traceplot
```{r, fig.width = 10, fig.height = 6}
traceplot(
  model_list_surv$weibull, 
  pars = c("alpha", "beta_0", "beta"),
  ncol = 3L
)
```

## Posterior calibration (1)
```{r, fig.width = 10, fig.height = 6}
stan_model <- model_list_surv$weibull

y_rep <- as.matrix(stan_model, pars = c("y_rep"))

# Check if the replicated data makes sense with respect to
# the observed data
# Compare posterior with observed
ppc_dens_overlay(y = db_ovarian_scaled$futime, yrep = y_rep[1:200, ]) +
  xlim(0, 50)

# Greater simulated follow-up times seem to be frequent...
```

## Posterior calibration (2)
```{r, fig.width = 10, fig.height = 4}
# Compare some quantiles of follow-up times
ppc_median <- ppc_stat(
  y = db_ovarian_scaled$futime, yrep = y_rep[1:200, ], stat = "median"
)

# ... also by group of treatment
ppc_median_grouped <- ppc_stat_grouped(
  y = db_ovarian_scaled$futime, yrep = y_rep[1:200, ],
  group = db_ovarian_scaled[["rx"]], stat = "median"
)

ggpubr::ggarrange(
  ppc_median, ppc_median_grouped, ncol = 2L, nrow = 1L
)
```

## Posterior calibration (3)
```{r, fig.width = 10, fig.height = 4}
first_quart <- function(x) quantile(x, probs = 0.25)
third_quart <- function(x) quantile(x, probs = 0.75)

ppc_first <- ppc_stat(
  y = db_ovarian_scaled$futime, yrep = y_rep[1:200, ],
  stat = "first_quart"
)

ppc_third <- ppc_stat(
  y = db_ovarian_scaled$futime, yrep = y_rep[1:200, ],
  stat = "third_quart"
)

ggpubr::ggarrange(
  ppc_first, ppc_third, ncol = 2L, nrow = 1L
)
```

## Revise the model

\begin{itemize}
  \item{The model predicts greater follow-up times than those observed
        in the ovarian cancer data}
  \item{Weibull distribution may not be the best one to model 
        time-to-deaths of subjects with ovarian cancer}
  \item{Different family distributions can be considered, e.g.
        log-normal, gamma, ...}
\end{itemize}

## Log-normal (1)
```{r, fig.width = 10, fig.height = 6}
stan_model <- model_list_surv$lognormal

y_rep <- as.matrix(stan_model, pars = c("y_rep"))

# Check if the replicated data makes sense with respect to
# the observed data
# Compare posterior with observed
ppc_dens_overlay(y = db_ovarian_scaled$futime, yrep = y_rep[1:200, ]) +
  xlim(0, 50)

# Greater simulated follow-up times seem to be frequent...
```

## Log-normal (2)
```{r, fig.width = 10, fig.height = 4}
# Compare some quantiles of follow-up times
ppc_median <- ppc_stat(
  y = db_ovarian_scaled$futime, yrep = y_rep[1:200, ], stat = "median"
)

# ... also by group of treatment
ppc_median_grouped <- ppc_stat_grouped(
  y = db_ovarian_scaled$futime, yrep = y_rep[1:200, ],
  group = db_ovarian_scaled[["rx"]], stat = "median"
)

ggpubr::ggarrange(
  ppc_median, ppc_median_grouped, ncol = 2L, nrow = 1L
)
```

## Log-normal (3)
```{r, fig.width = 10, fig.height = 4}
first_quart <- function(x) quantile(x, probs = 0.25)
third_quart <- function(x) quantile(x, probs = 0.75)

ppc_first <- ppc_stat(
  y = db_ovarian_scaled$futime, yrep = y_rep[1:200, ],
  stat = "first_quart"
)

ppc_third <- ppc_stat(
  y = db_ovarian_scaled$futime, yrep = y_rep[1:200, ],
  stat = "third_quart"
)

ggpubr::ggarrange(
  ppc_first, ppc_third, ncol = 2L, nrow = 1L
)
```

## Gamma (1)
```{r, fig.width = 10, fig.height = 6}
stan_model <- model_list_surv$lognormal

y_rep <- as.matrix(stan_model, pars = c("y_rep"))

# Check if the replicated data makes sense with respect to
# the observed data
# Compare posterior with observed
ppc_dens_overlay(y = db_ovarian_scaled$futime, yrep = y_rep[1:200, ]) +
  xlim(0, 50)

# Greater simulated follow-up times seem to be frequent...
```

## Gamma (2)
```{r, fig.width = 10, fig.height = 4}
# Compare some quantiles of follow-up times
ppc_median <- ppc_stat(
  y = db_ovarian_scaled$futime, yrep = y_rep[1:200, ], stat = "median"
)

# ... also by group of treatment
ppc_median_grouped <- ppc_stat_grouped(
  y = db_ovarian_scaled$futime, yrep = y_rep[1:200, ],
  group = db_ovarian_scaled[["rx"]], stat = "median"
)

ggpubr::ggarrange(
  ppc_median, ppc_median_grouped, ncol = 2L, nrow = 1L
)
```

## Gamma (3)
```{r, fig.width = 10, fig.height = 4}
first_quart <- function(x) quantile(x, probs = 0.25)
third_quart <- function(x) quantile(x, probs = 0.75)

ppc_first <- ppc_stat(
  y = db_ovarian_scaled$futime, yrep = y_rep[1:200, ],
  stat = "first_quart"
)

ppc_third <- ppc_stat(
  y = db_ovarian_scaled$futime, yrep = y_rep[1:200, ],
  stat = "third_quart"
)

ggpubr::ggarrange(
  ppc_first, ppc_third, ncol = 2L, nrow = 1L
)
```

## Compare the models (1)
\begin{itemize}
\setlength\itemsep{1em}
  \item{Models can be compared using leave-one-out cross-validation
        (LOO-CV)}
  \item{Expected log predictive density (ELPD) computed with LOO-CV
        can be used to evaluate which model has a better fit}
  \item{Predictive weights can be assigned to each model by using
        Stacking, Pseudo bayesian-model-averaging (Pseudo-BMA) and
        Pseudo bayesian-model-averaging with Bayesian Bootstrap
        (Pseudo-BMA BB)}
  \item{Higher ELPD and predictive weights suggest better 
        predictive performances}
\end{itemize}

## Compare the models (2)
\scriptsize
```{r}
loo_comp <- compare(x = loo_list_surv) %>% 
  tidy() %>% 
  rename(model = .rownames) %>% 
  dplyr::select(model:se_elpd_loo) %>% 
  mutate_at(vars(elpd_diff:se_elpd_loo), funs(round(., 3L)))

weights_comp <- data_frame(
  model = names(stacking_weights_surv),
  stacking = stacking_weights_surv,
  pseudo_bma = pseudo_bma_surv,
  pseudo_bma_bb = pseudo_bma_bb_surv
) %>% 
  mutate_at(vars(stacking:pseudo_bma_bb), funs(round(., 3L)))

kable(
  loo_comp, digits = 2L,
  caption = "Comparison of ELPD of the fitted models."
)

kable(
  weights_comp, digits = 2L,
  caption = "Model comparison with Stacking, Pseudo-BMA and 
             Pseudo-BMA with Bayesian Bootstrap."
)
```

## Parameters of the model (1)
```{r, fig.width = 10, fig.height = 6}
coef_lognormal <- as.data.frame(
  model_list_surv$lognormal, pars = c("sigma", "beta_0", "beta")
) %>%
  setNames(
    object = .,
    nm = c(
      "sigma", "intercept", "age", "residual_disease",
      "ecog_perf", "treatment"
    )
  )

mcmc_intervals(coef_lognormal)
```

## Parameters of the model (2)
```{r, fig.width = 10, fig.height = 6}
mcmc_areas(coef_lognormal)
```

## Posterior predictive survival curves
```{r, fig.width = 10, fig.height = 6}
lognormal_survplot
```

## Therapy efficacy
```{r}
prob_eff_2 <- mean(post_eff_2 > 0.10)
```

Now we want to assess the efficacy of the new therapy with respect to
the standard therapy.

- Suppose that the new therapy is consider to be more effective than
  the standard one if it produces at least a $10 \%$ increase in the
  survival probability at $2$-years follow-up. 
  
- Given the model, we observe a $75.9 \%$ chance that the
  Cyclophosphamide plus Adriamycin therapy will be more effective than
  the Cyclophosphamide alone therapy.

# Logistic Regression Case Study


## Influenza vaccine case study
- Hospitalized adults with acute respiratory disease tested for 
  influenza with laboratory test (RT-PCR) [@talbot_2013]
  

- The aim of the study was to estimate vaccine effectiveness in reducing
  risk of influenza
  
  
- Case-positive, control-negative study design


- Low prevalence of influenza ($\approx 10 \%$)

## The data
- Data were simulated from the information provided by 
  _Chen et al. (2016)_ [@chen_2016]:
  
  
- $200$ subjects


- $19$ with positive influenza status and $119$ with verified
  vaccination status
  
      
- The following confounders: race, home oxygen use, current smoking
  status, diabetes mellitus, asthma chronic obstructive pulmonary
  disease, chronic heart disease, immunosuppression,
  chronic liver or kidney disease, asplenia, other type of disease,
  age and timing of admission relative to the onset of influenza
  season

## The goal

- With low number of cases and high number of covariates a standard
  logistic regression would overfit the data
  
  
- In their study, _Chen et al. (2016)_ showed the benefits of penalizing
  maximum likelihood estimates (MLE) of all the terms in the model but
  the one related to the vaccination status
  
  
- Control both for overfitting and bias in the exposure estimate


- How can prior distributions help in such situations?

## Non-informative uniform priors 

## Non-informative uniform priors
```{r, fig.width = 10, fig.height = 5}
model_list_logit <- model_list %>% 
  setNames(
    object = ., nm = c(
      "uniform", "vague", "cauchy", "student_t_3", "student_t_7",
      "student_t_3_unp", "student_t_7_unp"
    )
  )

color_scheme_set("red")
mcmc_hist(post_coefs_uniform)
```

## Non-informative uniform priors
```{r, fig.width = 10, fig.height = 5}
rhats <- rhat(model_list_logit$uniform, pars = c("alpha", "beta"))
mcmc_rhat(rhats)
```

## Non-informative uniform priors
- Coefficients estimates are too extreme to be plausible


- The algorithm did not perform a good sample of the posterior:
    - Many divergent transitions
    - Low $R_{hat}$ and $ESS$ values
    

- The model likely overfitted the data


- Priors that allow for less extreme values may help

## Vague priors: $N \sim \left( 0, 100 \right)$

## Vague priors: $N \sim \left( 0, 100 \right)$
```{r, fig.width = 10, fig.height = 5}
mcmc_hist(post_coefs_vague)
```

## Vague priors: $N \sim \left( 0, 100 \right)$
```{r, fig.width = 10, fig.height = 5}
rhats <- rhat(model_list_logit$vague, pars = c("alpha", "beta"))
mcmc_rhat(rhats)
```

## $Cauchy \sim \left( 0, 2.5 \right)$
```{r, fig.width = 10, fig.height = 5}
mcmc_hist(post_coefs_cauchy)
```

## $Cauchy \sim \left( 0, 2.5 \right)$
```{r, fig.width = 10, fig.height = 5}
rhats <- rhat(model_list_logit$cauchy, pars = c("alpha", "beta"))
mcmc_rhat(rhats)
```

## Weakly informative priors
- $Cauchy \sim \left( 0, 2.5 \right)$ improved the fit, but 
  overfitting may be still present given the high values of coefficients
  
  
- Weakly informative priors may help in such situations to regularize
  inference by shrinking regression coefficients to $0$
  
  
- The idea is to give more probability to values near the $0$ while
  giving at the same time some chances to higher values
  
  
- If covariates are roughly on unit scale, 
  $t-student \sim \left(df, 0, 1 \right)$ with $3 \leq df \leq 7$ is
  a reasonable choice for logistic regression models
  
## T-student priors: coefficients
```{r, fig.height = 6, fig.width = 10}
coef_student_3 <- post_coefs_student_3 %>% 
  map_df(
    .x = .,
    ~ data_frame(
      post_median = median(.x), 
      lower_70 = quantile(.x, probs = 0.15), 
      upper_70 = quantile(.x, probs = 0.85),
      lower_90 = quantile(.x, probs = 0.05),
      upper_90 = quantile(.x, probs = 0.95)
    )
  ) %>% 
  mutate(
    term = names(post_coefs_student_3),
    prior = "3 df"
  )

coef_student_7 <- post_coefs_student_7 %>% 
  map_df(
    .x = .,
    ~ data_frame(
      post_median = median(.x), 
      lower_70 = quantile(.x, probs = 0.15), 
      upper_70 = quantile(.x, probs = 0.85),
      lower_90 = quantile(.x, probs = 0.05),
      upper_90 = quantile(.x, probs = 0.95)
    )
  ) %>% 
  mutate(
    term = names(post_coefs_student_7),
    prior = "7 df"
  )

post_coef_stud <- bind_rows(coef_student_3, coef_student_7) %>% 
  mutate(
    term = factor(term, levels = rev(names(post_coefs_student_7)))
  )

ggplot(
  data = post_coef_stud, 
  mapping = aes(x = post_median, y = term, colour = prior, fill = prior)
) + 
  geom_point(
    size = 1.5, 
    position = ggstance::position_dodgev(height = 0.4)
  ) +
  geom_errorbarh(
    mapping = aes(xmin = lower_70, xmax = upper_70),
    size = 0.9, position = ggstance::position_dodgev(height = 0.4),
    height = 0
  ) +
  geom_errorbarh(
    mapping = aes(xmin = lower_90, xmax = upper_90),
    size = 0.7, position = ggstance::position_dodgev(height = 0.4),
    height = 0
  ) +
  geom_vline(xintercept = 0, linetype = "dashed") +
  scale_fill_manual(
    name = "T-student prior",
    values = c("dodgerblue2", "firebrick4"),
    labels = c("3 df", "7 df")
  ) +
  scale_colour_manual(
    name = "T-student prior",
    values = c("dodgerblue2", "firebrick4"),
    labels = c("3 df", "7 df")
  ) +
  xlab("Posterior estimates") +
  ylab("Model's coefficients") +
  scale_x_continuous(breaks = seq(from = -6, to = 6, by = 1)) + 
  theme_classic()
```

## T-student priors: posterior checks (1)
```{r, fig.height = 6, fig.width = 10}
y <- if_else(db_logit$influenza == "Yes", 1, 0)
yrep_3 <- as.matrix(model_list_logit$student_t_3, pars = "y_rep")

yrep_7 <- as.matrix(
  model_list_logit$student_t_7, pars = c("y_rep")
)

prop_zero <- function(x) mean(x == 0)
prop_one <- function(x) mean(x == 1)

prop_zero_3 <- ppc_stat(
  y = y, yrep = yrep_3[1:200,], stat = "prop_zero"
) +
  ggtitle("3 df")

prop_zero_7 <- ppc_stat(
  y = y, yrep = yrep_7[1:200,], stat = "prop_zero"
) +
  ggtitle("7 df")

prop_one_3 <- ppc_stat(
  y = y, yrep = yrep_3[1:200,], stat = "prop_one"
) +
  ggtitle("3 df")

prop_one_7 <- ppc_stat(
  y = y, yrep = yrep_7[1:200,], stat = "prop_one"
) +
  ggtitle("7 df")

ggpubr::ggarrange(
  prop_zero_3, prop_zero_7, ncol = 2L, nrow = 1L
)
```

## T-student priors: posterior checks (2)
```{r, fig.height = 6, fig.width = 10}
ggpubr::ggarrange(
  prop_one_3, prop_one_7, ncol = 2L, nrow = 1L
)
```

## T-student priors: model comparison and averaging
```{r}
weights_comp_logit <- data_frame(
  model = names(pseudo_bma),
  stacking = stacking_weights,
  pseudo_bma = pseudo_bma,
  pseudo_bma_bb = pseudo_bma_bb
) %>% 
  mutate_at(vars(stacking:pseudo_bma_bb), funs(round(., 3L)))


kable(
  weights_comp_logit, digits = 2L,
  caption = "Model comparison with Stacking, Pseudo-BMA and 
             Pseudo-BMA with Bayesian Bootstrap."
)
```

## Vaccine effectiveness
```{r, fig.height = 6, fig.width = 10}
true_eff <- (1 - exp(true_betas[length(true_betas)])) * 100

vaccine_eff_fun <- function(x) (1 - exp(x)) * 100

list_post_coef <- list(
  post_coefs_student_3, post_coefs_student_7, post_coefs_student_3_unp,
  post_coefs_student_7_unp
) 

vaccine_eff_df <- map(
  .x = list_post_coef,
  ~ .x[["vaccine"]] %>% 
    vaccine_eff_fun(x = .)
) %>% 
  setNames(
    object = ., nm = c(
      "student_3", "student_7",
      "student_3_unp", "student_7_unp"
    )
  ) %>% 
  as_data_frame() %>% 
  map_df(
    .x = .,
    ~ data_frame(
      post_median = median(.x), 
      lower_70 = quantile(.x, probs = 0.15), 
      upper_70 = quantile(.x, probs = 0.85),
      lower_90 = quantile(.x, probs = 0.05),
      upper_90 = quantile(.x, probs = 0.95)
    )
  ) %>% 
  mutate(
    prior = factor(
      c(
        "student_3", "student_7",
      "student_3_unp", "student_7_unp"
    ), levels = c(
      "student_3", "student_7",
      "student_3_unp", "student_7_unp"
    )
    )
  )

ggplot(
  data = vaccine_eff_df,
  mapping = aes(
    x = post_median, y = prior
  )
) +
  geom_errorbarh(
    mapping = aes(xmin = lower_90, xmax = upper_90),
    size = 1, position = ggstance::position_dodgev(height = 0.4),
    height = 0, colour = "firebrick1"
  ) +
  geom_errorbarh(
    mapping = aes(xmin = lower_70, xmax = upper_70),
    size = 1.6, position = ggstance::position_dodgev(height = 0.4),
    colour = "firebrick3", height = 0
  ) +
  geom_point(
    size = 2.5, 
    position = ggstance::position_dodgev(height = 0.4), 
    colour = "firebrick"
  ) +
  xlab("(1 - OR) x 100 posterior estimates") +
  ylab("Model's priors") + 
  theme_classic()
```

## Vaccine effectiveness
```{r, fig.height = 6, fig.width = 10}
# Assessing effectiveness with stacking weights
vaccine_df <- data_frame(
  iter = rep(1:4000, 4L),
  model = rep(names(stacking_weights), each = 4000),
  wts = rep(stacking_weights, each = 4000),
  post = c(
    post_coefs_student_3[["vaccine"]], 
    post_coefs_student_7[["vaccine"]],
    post_coefs_student_3_unp[["vaccine"]], 
    post_coefs_student_7_unp[["vaccine"]]
  ),
  eff = (1 - exp(post)) * 100
) %>% 
  group_by(iter) %>% 
  summarize(avg_eff = sum(eff * wts))

ggplot(
  data = vaccine_df, mapping = aes(x = avg_eff)
) +
  geom_histogram(
    colour = "forestgreen", fill = "forestgreen", alpha = 0.2,
    bins = 100
  ) +
  xlab("Averaged (1 - OR) * 100") +
  ylab("") +
  theme_bw()

avg_eff <- mean(vaccine_df[["avg_eff"]] > 70)
```

## Vaccine effectiveness
Now we want to assess the efficacy of the vaccine in preventing 
influenza-associated acute respiratory hospitalizations in adults.

\begin{itemize}
\setlength\itemsep{1em}
  \item{Suppose that the vaccine is considered to be effective if
        $(1 - OR) * 100$ is at least $70 \%$}
  \item{Given the averaged estimate of vaccine effectiveness (using
        the weights produced by stacking), it is
        possible to assess that the vaccine will be effective in
        preventing influenza $85.98 \%$ of the times}
\end{itemize}

## Additional information  
- Stan's website at [http://mc-stan.org/](http://mc-stan.org/). Here
  you can find the reference manual, videos, tutorials, case studies and
  so on
  
- Here's a list of R packages that interface with Stan:
    - __rstan__
    - __bayesplot__
    - __loo__ 
    - __brms__ 
    - __rstanarm__ 
    - __trialr__ 
    - __RBesT__ 
    - __survHE__

- The slides of the presentation, the R and Stan codes used for the
  case studies are at 
  [https://github.com/danielebottigliengo/IBIG_2018](https://github.com/danielebottigliengo/IBIG_2018)
  
## References
\footnotesize
